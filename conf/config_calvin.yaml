defaults:
  - callbacks: calvin
  - datamodule: calvin
  - model: depth_agent
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

#cam_file: /home/huang/david/MoDE/mode/utils/cam_params.pkl
cam_file: /home/david/Nips2025/MoDE/mode/utils/cam_params.pkl

root_data_dir: /home/david/Nips2025/MoDE/calvin/dataset/calvin_debug_dataset
#root_data_dir: /hkfs/work/workspace/scratch/ft4740-play3/data/task_ABC_D
lang_folder: lang_annotations
vis_clip_model_name: ViT-B/16
clip_lang_model_name: ViT-B/32

log_dir: ./logs
slurm: false
seed: 242
device: 'cuda'
batch_size: 64 # 38 # 128
devices: 1
action_dim: 7
proprio_dims: 7
obs_dim: 512
#goal_dim: 512
obs_seq_len: 1
act_seq_len: 10
multistep: 10 #${act_seq_len}
p_last_state: 0
gen_img_res: 112
max_epochs: 25
rollout_lh_skip_epochs: 9
num_workers: 12
benchmark_name: nips_calvin_final # calvin_abcd
use_extracted_rel_actions: true

##########################################################################################
# Common Parameters
##########################################################################################
n_embd: 512
goal_dim: 512
latent_dim: 2048

obs_tokens: 120 #${obs_seq_len}
use_pos_emb: True
num_sampling_steps: 10
goal_conditioned: True
goal_window_size: 1

##########################################################################################
# Transformer Parameters (encoder-decoder)
##########################################################################################
encoder_n_layer: 8
decoder_n_layer: 6
n_heads: 8

##########################################################################################
# Mamba Parameters
##########################################################################################
Mamba_type: Mamba1

mamba_n_layer_encoder: 10
mamba_encoder_cfg:
  layer: ${Mamba_type}
  d_state: 64
  d_conv: 4
  expand: 2

##########################################################################################
# xLSTM Parameters
##########################################################################################
xlstm_encoder_blocks: 10
xlstm_encoder_vocab_size: 140
xlstm_encoder_chunkwise_kernel: "parallel--native_autograd"   # "parallel--native_autograd" "chunkwise--native_autograd"
xlstm_encoder_mode: "train"  # "train" "train_with_padding"
xlstm_encoder_adaLN_zero: False
xlstm_encoder_in_context_cond: False
xlstm_heads: 8

trainer:
  devices: ${devices}
  precision: bf16
  max_epochs: ${max_epochs}
  sync_batchnorm: True
  accelerator: gpu
  strategy: "ddp" 
  limit_train_batches: 1000
  limit_val_batches: 4



logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  save_dir: .
#  name: logger
  group: calvin
  log_model: false
  project: ${benchmark_name}
  entity: tiger_or_cat
#  id: ???


hydra:
  run:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}_seed${seed}
  sweep:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}
  job:
    config:
      override_dirname:
        exclude_keys:
          - log_dir
          - datamodule.root_data_dir
          - trainer.gpus
          - datamodule.num_workers
          - trainer.limit_train_batches
          - trainer.limit_val_batches
